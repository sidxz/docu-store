# Summary Embeddings & Hierarchical Search

## Overview

This document covers two closely related features:

1. **Summary Embedding Pipeline** — embed page and artifact summaries into a new unified
   Qdrant collection `summary_embeddings` after they are generated by the LLM.
2. **Hierarchical Search** — a search endpoint that queries both `page_chunks` (raw text)
   and `summary_embeddings` in parallel, merges results, and returns a structured
   artifact → page → chunk hierarchy.

These build on top of the existing raw text embedding pipeline (`page_embeddings` collection)
and the page/artifact summarization features already implemented.

---

## Architecture Decision: One Unified Summary Collection

### Why not three separate collections?

We considered `page_summary_embeddings` + `artifact_summary_embeddings` + existing
`page_embeddings` but rejected it for cross-granularity search:

- Cosine similarity scores from different collections are **not directly comparable** —
  normalisation is non-trivial and approximate.
- Three parallel queries + client-side score normalisation + merge is complex.
- A 0.85 score from an artifact summary and a 0.85 from a page chunk don't mean equal
  relevance; unified ranking requires a shared score space.

### Why not a single collection for everything?

Merging raw text chunks into the same collection as summaries breaks HNSW quality:

- Raw text chunks are high-cardinality (many per page), summaries are low-cardinality.
- HNSW graph structure is dominated by the most common vector type — artifact summary
  vectors end up surrounded by chunk vectors in the approximate-neighbor graph, degrading
  recall for the rarer type.
- Semantic granularity is different: chunks are noisy/partial, summaries are
  LLM-distilled.

### Decision: Two collections

```
page_embeddings      existing — raw text chunks (multiple per page), dense only
                     → "find the exact passage"

summary_embeddings   new unified — page summaries + artifact summaries, dense + sparse
                     → "find pages/documents about X"

compound_embeddings  existing — SMILES/ChemBERTa, separate domain
```

The `summary_embeddings` collection has manageable cardinality (~pages × artifacts,
typically 2 000–10 000 vectors), so HNSW quality is unaffected by type mixing within it.
Page and artifact summaries are both LLM-distilled text — their score distributions are
comparable, enabling direct ranking across types.

---

## Why Hybrid Search (Dense + Sparse)?

The biomedical domain has many **exact-identifier queries**: compound codes (`SACC-111`),
gene/protein names (`NadD`), institution abbreviations (`TAMU`). Dense embeddings handle
semantic meaning but may not have seen these specific tokens and produce low similarity.
Sparse vectors (BM25/SPLADE) guarantee exact-term recall.

Hybrid = dense (semantic recall) + sparse (exact-term recall), fused with RRF
(Reciprocal Rank Fusion). Qdrant's Query API supports this natively with a single
server-side request.

Example query: `"NadD with compound SACC-111 by TAMU"`
- Dense: high score for slides about NadD inhibition and lead optimisation
- Sparse: guaranteed match on `SACC-111`, `NadD`, `TAMU` tokens
- RRF fusion: best of both

**Phase 1**: implement dense-only for summary collection (same model as `page_embeddings`).
**Phase 2**: add sparse vectors + hybrid RRF (requires SPLADE model integration).
This doc covers both phases but Phase 1 is the implementation priority.

---

## Collection Schema: `summary_embeddings`

### Point structure

```
{
  id:      <entity_uuid>,          # page_id or artifact_id

  vectors: {
    "dense":  [float × 384],       # all-MiniLM-L6-v2, same as page_embeddings
    "sparse": {indices: [...], values: [...]}   # Phase 2: SPLADE/BM25
  },

  payload: {
    "type":           "page_summary" | "artifact_summary",

    # always present
    "entity_id":      "<uuid>",     # same as point id, for clarity
    "artifact_id":    "<uuid>",
    "artifact_title": "TAMU_NadD_2024.pptx",
    "summary_text":   "This slide presents IC50 data...",   # for result display
    "model_name":     "ollama/gemma3:27b",
    "date_embedded":  "2025-01-15T12:34:56Z",

    # page_summary only
    "page_id":        "<uuid>",
    "page_index":     3,            # 0-based

    # artifact_summary only
    "page_count":     24
  }
}
```

Storing `summary_text` in the payload means search results are **self-contained** —
no round-trip to MongoDB needed to display the snippet.

### Qdrant collection config (Phase 1: dense only)

```python
VectorsConfig(
    "dense": VectorParams(
        size=384,
        distance=Distance.COSINE,
    )
)
```

### Qdrant collection config (Phase 2: named vectors with sparse)

```python
VectorsConfig(
    "dense": VectorParams(size=384, distance=Distance.COSINE),
)
SparseVectorsConfig(
    "sparse": SparseVectorParams(modifier=Modifier.IDF)
)
```

---

## Embedding Pipeline

### Trigger events

| Event | Source | Action |
|-------|--------|--------|
| `Page.SummaryCandidateUpdated` | pipeline_worker | embed page summary → `summary_embeddings` |
| `Artifact.SummaryCandidateUpdated` | pipeline_worker | embed artifact summary → `summary_embeddings` |

These run concurrently with other reactions to the same events (e.g.
`Page.SummaryCandidateUpdated` also triggers `TriggerArtifactSummarizationUseCase`).
No domain conflict — Qdrant upsert is independent of the EventStoreDB aggregate.

### Re-embedding on update

Qdrant upsert by entity UUID overwrites the existing vector if the summary is
regenerated. No special handling needed.

### No new domain events required

Unlike `TextEmbeddingGenerated` (which was added to sequence the summarization pipeline),
summary embeddings have no downstream domain consumers. Qdrant is the source of truth;
nothing in the domain needs to react to "summary was embedded".

### Data flow

```
Page.SummaryCandidateUpdated
  → pipeline_worker
    → TriggerPageSummaryEmbeddingUseCase.execute(page_id)
        → EmbedPageSummaryUseCase (via Temporal activity)
            1. page_repository.get(page_id)
            2. artifact_repository.get(page.artifact_id)   # for artifact_title
            3. embedding_generator.generate(page.summary_candidate.summary)
            4. summary_vector_store.upsert_page_summary(page_id, vector, payload)
            5. Return success/failure

Artifact.SummaryCandidateUpdated
  → pipeline_worker
    → TriggerArtifactSummaryEmbeddingUseCase.execute(artifact_id)
        → EmbedArtifactSummaryUseCase (via Temporal activity)
            1. artifact_repository.get(artifact_id)
            2. embedding_generator.generate(artifact.summary_candidate.summary)
            3. summary_vector_store.upsert_artifact_summary(artifact_id, vector, payload)
            4. Return success/failure
```

### No chunking

Summaries are 2–10 sentences (~100–500 chars), well within a single embedding context
window. One vector per entity. No `TextChunker` needed.

---

## New Port: `SummaryVectorStore`

```python
class SummaryVectorStore(Protocol):

    async def ensure_collection_exists(self) -> None: ...

    async def upsert_page_summary(
        self,
        page_id: UUID,
        vector: list[float],
        payload: dict,
    ) -> None: ...

    async def upsert_artifact_summary(
        self,
        artifact_id: UUID,
        vector: list[float],
        payload: dict,
    ) -> None: ...

    async def delete_summary(self, entity_id: UUID) -> None: ...

    async def search_summaries(
        self,
        query_vector: list[float],
        limit: int = 20,
        filter_type: Literal["page_summary", "artifact_summary"] | None = None,
    ) -> list[SummarySearchResult]: ...
```

### `SummarySearchResult` DTO

```python
@dataclass
class SummarySearchResult:
    score: float
    type: Literal["page_summary", "artifact_summary"]
    entity_id: UUID
    artifact_id: UUID
    artifact_title: str
    summary_text: str
    model_name: str
    # page_summary only
    page_id: UUID | None = None
    page_index: int | None = None
    # artifact_summary only
    page_count: int | None = None
```

---

## New Use Cases

### `EmbedPageSummaryUseCase`

- Input: `page_id`
- Loads page + artifact (for title)
- Guards: skip if `page.summary_candidate is None`
- Calls `embedding_generator.generate_text_embedding(summary_text)`
- Calls `summary_vector_store.upsert_page_summary(...)`
- Returns `Result[dict, AppError]`

### `EmbedArtifactSummaryUseCase`

- Input: `artifact_id`
- Loads artifact
- Guards: skip if `artifact.summary_candidate is None`
- Calls `embedding_generator.generate_text_embedding(summary_text)`
- Calls `summary_vector_store.upsert_artifact_summary(...)`
- Returns `Result[dict, AppError]`

### `TriggerPageSummaryEmbeddingUseCase`

- Input: `page_id`
- Starts `PageSummaryEmbeddingWorkflow` via orchestrator
- Workflow ID: `page-summary-embedding-{page_id}`, ALLOW_DUPLICATE

### `TriggerArtifactSummaryEmbeddingUseCase`

- Input: `artifact_id`
- Starts `ArtifactSummaryEmbeddingWorkflow` via orchestrator
- Workflow ID: `artifact-summary-embedding-{artifact_id}`, ALLOW_DUPLICATE

---

## Temporal Workflows & Activities

### `PageSummaryEmbeddingWorkflow`

```python
@workflow.defn(name="PageSummaryEmbeddingWorkflow")
class PageSummaryEmbeddingWorkflow:
    async def run(self, page_id: str) -> dict:
        # single activity: embed_page_summary
        # timeout: 5 min (embedding is fast, no LLM call)
        # retry: 3 attempts, 5s → 60s backoff
```

### `ArtifactSummaryEmbeddingWorkflow`

```python
@workflow.defn(name="ArtifactSummaryEmbeddingWorkflow")
class ArtifactSummaryEmbeddingWorkflow:
    async def run(self, artifact_id: str) -> dict:
        # single activity: embed_artifact_summary
        # same timeouts/retries as page variant
```

Activities: `embed_page_summary_activity`, `embed_artifact_summary_activity`.
Both follow the factory pattern from existing activities.

---

## Workflow Orchestrator Port additions

```python
async def start_page_summary_embedding_workflow(self, page_id: UUID) -> None: ...
async def start_artifact_summary_embedding_workflow(self, artifact_id: UUID) -> None: ...
```

Workflow IDs:
- `page-summary-embedding-{page_id}`
- `artifact-summary-embedding-{artifact_id}`

Both use `ALLOW_DUPLICATE` reuse policy — re-triggered if summary is regenerated.

---

## Pipeline Worker additions

Subscribe to two new events:

```python
Page.SummaryCandidateUpdated   → TriggerPageSummaryEmbeddingUseCase
Artifact.SummaryCandidateUpdated → TriggerArtifactSummaryEmbeddingUseCase
```

`Page.SummaryCandidateUpdated` already triggers `TriggerArtifactSummarizationUseCase` —
these two use cases run independently (no shared state).

---

## Search: Hierarchical Results

### Search use case: `SearchSummariesUseCase`

```python
async def execute(
    self,
    query: str,
    limit: int = 10,
    filter_type: Literal["page_summary", "artifact_summary"] | None = None,
) -> list[SummarySearchResult]: ...
```

1. `embedding_generator.generate_text_embedding(query)`
2. `summary_vector_store.search_summaries(vector, limit, filter_type)`
3. Return results (already populated from Qdrant payload — no MongoDB round-trip)

### Search use case: `HierarchicalSearchUseCase`

Combines both collections for the full document-discovery experience:

```python
async def execute(self, query: str, limit: int = 5) -> list[ArtifactSearchResult]: ...
```

```
1. embed query (once)
2. parallel:
   A. summary_vector_store.search_summaries(vector, limit=50)
      → artifact_summary hits + page_summary hits
   B. vector_store.search_similar_pages(vector, limit=50)
      → raw chunk hits (existing)

3. group A by artifact_id:
   - for each artifact: collect its artifact_summary hit (if any) and its page_summary hits
   - rank artifacts by best score among their hits

4. for each top artifact, attach supporting chunks from B:
   - filter B results to this artifact_id
   - attach top 2-3 chunks per page

5. return ArtifactSearchResult list (see DTO below)
```

### `ArtifactSearchResult` DTO

```python
@dataclass
class PageSearchResult:
    page_id: UUID
    page_index: int
    score: float
    summary_snippet: str                    # from summary payload
    supporting_chunks: list[ChunkResult]    # from page_embeddings

@dataclass
class ArtifactSearchResult:
    artifact_id: UUID
    artifact_title: str
    score: float                            # best score among artifact+page hits
    summary_snippet: str | None             # from artifact summary payload
    pages: list[PageSearchResult]           # sorted by score desc
```

### Search API endpoints

```
GET /search/summaries?q=...&limit=...&type=page_summary|artifact_summary|all
    → list[SummarySearchResult]
    → direct summary collection query, type-filtered

POST /search/hierarchical
    body: { query: str, limit: int }
    → list[ArtifactSearchResult]
    → full cross-granularity search with chunk support
```

The existing `GET /search/pages` (raw chunk search) is unchanged.

---

## Phase 2: Hybrid Search (Dense + Sparse)

When SPLADE or BM25 sparse vector generation is added:

1. Add a `SparseEmbeddingGenerator` port (produces `{indices: list[int], values: list[float]}`).
2. Store sparse vector alongside dense in `summary_embeddings` under named vector `"sparse"`.
3. At search time, generate both dense and sparse query vectors.
4. Use Qdrant Query API with `prefetch` + `rrf` fusion:

```python
client.query_points(
    collection_name="summary_embeddings",
    prefetch=[
        Prefetch(query=dense_vector, using="dense", limit=100),
        Prefetch(query=SparseVector(indices, values), using="sparse", limit=100),
    ],
    query=FusionQuery(fusion=Fusion.RRF),
    limit=20,
    with_payload=True,
)
```

5. `page_embeddings` can also have sparse vectors added for hybrid chunk search.

Phase 2 is independent of Phase 1 — the collection schema supports named vectors from
the start, so adding sparse later is a non-breaking addition.

---

## Config additions

```python
# Summary embeddings collection
summary_embedding_collection_name: str = Field(
    default="summary_embeddings",
    validation_alias="SUMMARY_EMBEDDING_COLLECTION_NAME",
)
```

The same `embedding_model_name` / `embedding_device` config is reused — same model,
same vector space as `page_embeddings`.

---

## Files to create

| File | Role |
|------|------|
| `application/ports/summary_vector_store.py` | `SummaryVectorStore` Protocol + `SummarySearchResult` DTO |
| `application/dtos/search_dtos.py` | `ArtifactSearchResult`, `PageSearchResult`, `ChunkResult` DTOs |
| `application/use_cases/summary_embedding_use_cases.py` | `EmbedPageSummaryUseCase`, `EmbedArtifactSummaryUseCase` |
| `application/use_cases/search_use_cases.py` | `SearchSummariesUseCase`, `HierarchicalSearchUseCase` |
| `application/workflow_use_cases/trigger_page_summary_embedding_use_case.py` | Trigger workflow for page |
| `application/workflow_use_cases/trigger_artifact_summary_embedding_use_case.py` | Trigger workflow for artifact |
| `infrastructure/vector_stores/summary_qdrant_store.py` | `SummaryQdrantStore` — Qdrant adapter |
| `infrastructure/temporal/workflows/summary_embedding_workflow.py` | `PageSummaryEmbeddingWorkflow`, `ArtifactSummaryEmbeddingWorkflow` |
| `infrastructure/temporal/activities/summary_embedding_activities.py` | Two activity factories |
| `interfaces/api/routes/search_routes.py` | Add new search endpoints (file may already exist) |

## Files to modify

| File | Change |
|------|--------|
| `application/ports/workflow_orchestrator.py` | Add 2 new `start_*` methods |
| `infrastructure/temporal/orchestrator.py` | Implement 2 new methods |
| `infrastructure/temporal/worker.py` | Register 2 new workflows + 2 activities |
| `infrastructure/pipeline_worker.py` | Subscribe to `Page.SummaryCandidateUpdated` (already done), `Artifact.SummaryCandidateUpdated` (new); add 2 trigger use case calls |
| `infrastructure/config.py` | Add `summary_embedding_collection_name` |
| `infrastructure/di/container.py` | Wire `SummaryVectorStore`, 4 new use cases |

---

## Implementation order

1. **Config** — add `summary_embedding_collection_name`
2. **Port** — `application/ports/summary_vector_store.py`
3. **DTOs** — `application/dtos/search_dtos.py`
4. **Qdrant adapter** — `infrastructure/vector_stores/summary_qdrant_store.py`
   (dense-only, Phase 1; schema supports sparse for Phase 2)
5. **Embedding use cases** — `EmbedPageSummaryUseCase`, `EmbedArtifactSummaryUseCase`
6. **Trigger use cases** — `TriggerPageSummaryEmbeddingUseCase`, `TriggerArtifactSummaryEmbeddingUseCase`
7. **Temporal** — workflows + activities + register in worker
8. **Orchestrator** — add 2 new `start_*` methods
9. **Pipeline worker** — add `Artifact.SummaryCandidateUpdated` subscription; wire both triggers
10. **DI container** — wire everything
11. **Search use cases** — `SearchSummariesUseCase`, `HierarchicalSearchUseCase`
12. **Search API routes** — add endpoints

---

## Key design invariants

- **Same embedding model** as `page_embeddings` — vectors live in the same semantic space,
  enabling potential future cross-collection re-ranking.
- **No new domain events** — Qdrant is the source of truth for embedding state. The domain
  model is not polluted with operational embedding metadata.
- **Upsert is idempotent** — re-summarization automatically re-embeds; no special handling.
- **Payload is self-contained** — `summary_text`, `artifact_title`, `page_index` stored in
  Qdrant payload. Search results require no MongoDB round-trip for display.
- **Artifact summary subscription** in pipeline_worker is new — `Artifact.SummaryCandidateUpdated`
  was not previously subscribed to. Note: this event fires for both automated pipeline
  completions and manual `PATCH /artifacts/{id}/summary_candidate` API calls. Both should
  trigger re-embedding.
- **Phase 1 / Phase 2 split** — dense-only collection schema supports named vectors so
  sparse can be added later without rebuilding. The `SummaryVectorStore` port interface
  is designed to accommodate hybrid search in Phase 2 via a `sparse_vector` optional param.
